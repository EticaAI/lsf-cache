Codicem,"Lingua Anglica (Abecedarium Latinum), meta",Lingua Anglica (Abecedarium Latinum),C≈çdex fact≈ç,C≈çdex fact≈ç; meta
#item+conceptum+codicem,#meta+rem+i_eng+is_latn,#item+rem+i_eng+is_latn,#item+rem+i_qcc+is_zxxx+ix_codexfacto,#meta+rem+i_qcc+is_zxxx+ix_codexfacto
0_1603_1_7_2616_50,,,EticaAI,
0_1603_1_7_2616_123,,,EticaAI,
0_1603_1_7_2616_2479,,,CC0-1.0,Creative Commons Zero v1.0 Universal
0_1603_1_7_2616_577,,,2022-04-14,
0_1603_1_7_2616_7535,,,TODO: explain 1603_1_99,
1,,fƒ´at l≈´x!,,
2,,{% _üó£Ô∏è 1603_1_99_1 üó£Ô∏è_ %},,
2,Used on Methodƒ´ ex c≈çdice / Rƒìs interlinguƒÅlibus,The result of this section is a preview. We're aware it is not well (Abecedarium formatted for a book format. Sorry for the temporary inconvenience.,,
10,,/General text hardcoded on the 1603_1.py/,,
10_1,,"_**C≈çdex [{0}]**_ is the book format of the machine-readable dictionaries _**[{0}] {1}**_, which are distributed for implementers on external applications. This book is intended as advanced resource for other lexicographers and terminology translators, including detect and report inconsistencies.\n\nPractical lexicography is the art or craft of compiling, writing and editing dictionaries. The basics are not far different than a millennia ago: it is still a very humane, creative work. It is necessary to be humble: most of the translator's mistakes are, in fact, not translator's fault, but methodological flaws. Making sure of a source idea of what a concept represents, even if it means rewrite and make simpler, annex pictures, show examples, do whatever to make it be understood, makes even non-professional translators that care about their own language deliver better results than any alternative. In other words: even the so-called industry best practices of paying professional translators and reviewers cannot overcome already poorly explained source terms.\n\nThe initiative behind this compilation is also doing other dictionaries and accepts new suggestions of relevant topics on data exchange for humanitarian use. All have in common the fact that both have human translations and (if any) external interlingual codes related to each concept while making the end result explicitly already ready to be usable on average softwares. Naturally, each book version gives extensive explanations for collaborators on how to correct itself which become part of the next weekly release.",,
10_2,,"**Context information**: ignoring for a moment the fact of having several translations (and optimized to receive contributions on a regular basis, not _just_ an static work), then the actual groundbreaking difference on the workflow used to generate every dictionaries on C≈çdex such as this one are the following fact: **we provide well machine readable formats even when the equivalents on _international languages_, such as English, don't have for areas such as humanitarian aid, development aid and human rights**. The closest to such multilingualism (outside Wikimedia) are European Union SEMICeu (up to 24 languages), but even then have issues while sharing translations on all languages. United Nations translations (up to 6 languages, rarely more) are not available by humanitarian agencies to help with terminology translations.\n\n**Practical implication**: machine-readable formats on _Archƒ´a pr≈ç dicti≈çnƒÅriƒ´s_ (literal English translation: Files for dictionaries) are the focus and recommended for derived works and intended for mitigating additional human errors. We can even create new formats by request. The text documents on _Archƒ´a pr≈ç c≈çdice_ (literal English translation: Files for book) are alternatives to this book format.",,
10_2_0,,"Every book comes with several files both for book format (with (Abecedarium additional information) and machine-readable formats with Latinum) documentation of how to process them. If you receive this file and cannot find the alternatives, ask the human who provide this file.",,
10_3,,"WARNING: Unless you are working with a natural language you understand it\'s letters and symbols, it is strongly advised to use automation to generate derived works. Keep manual human steps at minimum: if something goes wrong at least one or more languages can be used to verify mistakes. It's not at all necessary _know all languages_, but working with writing systems you don't understand is risky: copy and paste strategy can cause _additional_ human errors and is unlikely to get human review as fast as you would need.",,
10_4,,TIP: The Asciidoctor (.adoc) is better at copy and pasting! It can be converted to other text formats.,,
10_5,,"NOTE: /At the moment, there is no workflow to use https://www.wikidata.org/wiki/Wikidata:Lexicographical_data[Wikidata lexicographical data], which actually could be used as storage for stricter nomenclature. The current implementations use only Wikidata concepts, the Q-items./@eng-Latn",,
10_6,,"The ***[{1}] {2}*** uses Wikidata as one strategy to conciliate language terms for one or more of it's concepts.\n\nThis means that this book, and related dictionaries data files require periodic updates to, at bare minimum, synchronize and re-share up to date translations.",,
10_7,,"**How reliable are the community translations (Wikidata source)?**\n\nThe short, default answer is: **they are reliable**, even in cases of no authoritative translations for each subject.\n\nAs reference, it is likely a professional translator (without access to Wikipedia or Internal terminology bases of the control organizations) would deliver lower quality results if you do blind tests. This is possible because not just the average public, but even terminologists and professional translators help Wikipedia (and implicitly Wikidata).\n\nHowever, even when the result is correct, the current version needs improved differentiation, at minimum, acronym and long form. For major organizations, features such as __P1813 short names__ exist, but are not yet compiled with the current dataset.",,
10_8,,"**Major reasons for ""wrong translations"" are not translators fault**\n\nTIP: As a rule of thumb, for already very defined concepts where you, as human, can manually verify one or more translated terms as a decent result, the other translations are likely to be acceptable. Dictionaries with edge cases (such as disputed territory names) would have further explanation.\n\nThe main reason for ""wrong translations"" are poorly defined concepts used to explain for community translators how to generate terminology translations. This would make existing translations from Wikidata (used not just by us) inconsistent. The second reason is if the dictionaries use translations for concepts without a strict match; in other words, if we make stricter definitions of what concept means but reuse Wikidada less exact terms. There are also issues when entire languages are encoded with wrong codes. Note that all these cases **wrong translations are strictly NOT translators fault, but lexicography fault**.\n\nIt is still possible to have strict translation level errors. But even if we point users how to correct Wikidata/Wikipedia (based on better contextual explanation of a concept, such as this book), the requirements to say the previous term was objectively a wrong human translation error (if following our seriousness on dictionary-building) are very high.",,
10_9,,"From the point of view of data conciliation, the following methodology is used to release the terminology translations with the main concept table.\n\n. The main handcrafted lexicographical table (explained on previous topic), also provided on `{0}.no1.tm.hxl.csv`, may reference Wiki QID.\n. Every unique QID of  `{0}.no1.tm.hxl.csv`, together with language codes from [`1603:1:51`] (which requires knowing human languages), is used to prepare an SPARQL query optimized to run on https://query.wikidata.org/[Wikidata Query Service]. The query is so huge that it is not viable to ""Try it"" links (URL overlong), such https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples[as what you would find on Wikidata Tutorials], ***but*** it works!\n.. Note that the knowledge is free, the translations are there, but the multilingual humanitarian needs may lack people to prepare the files and shares then for general use.\n. The query result, with all QIDs and term labels, is shared as `{0}.wikiq.tm.hxl.csv`\n. The community reviewed translations of each singular QID is pre-compiled on an individual file `{0}.wikiq.tm.hxl.csv`\n. `{0}.no1.tm.hxl.csv` plus `{0}.wikiq.tm.hxl.csv` created `{0}.no11.tm.hxl.csv`",,
10_10,,"This section explains the methodology of this book and it's machine readable formats. For your convenience the information used to explain the concepts (such as natural language and interlingual codes) which appears in this book are also summarized here. This approach is done both for reviews not needing to open other books (or deal with machine readable files) and also to spot errors on other dictionaries. +++<br><br>+++ About how the book and the dictionaries are compiled, a division of ""baseline concept table"" and (when relevant for a codex) ""translations conciliation"" is given different methodologies. +++<br><br>+++ Every book contains at minimum the baseline concept table and explanation of the used fields. This approach helps to release dictionaries faster while ensuring both humans and machines can know what to expect even when they are not ready to receive translations.",,
10_11,,"While the previous section presented the linguistic information (e.g. natural languages list) from [[1603:1:51]] restricted to what this book edition de facto has, this section gives a quick summary of Interlinguistic Information of [[1603:1:7]]. By Interlinguistic, it can be either true, language neutral codes (such as numbers) or computer codes which actually are mnemonics using some non neutral writing system. Interlinguistic, in the worst case, means some sort of _external identifier_ likely to be usable as a machine readable identifier.\n\nThe next section, **Archƒ´a** (literal English translation: Files) will only show [[{0}]] direct related files. But the complete [[1603:1:51]] and [[1603:1:7]] are available and licensed under public domain which makes them very friendly to derived works while mitigating implementers _additional_ errors.",,
10_12,,"Ignoring for a moment the fact of having several translations (and optimized to receive contributions on a regular basis), then the actual groundbreaking difference every dictionaries on C≈çdex such as this one are the following fact: **we provide well documented machine readable formats** even when the equivalents in English don't have.",,
20,,Desambiguation betwen dictionaries,,
20_1,,"\n\n**RELATED DICTIONARIES**\n\n\nThis namespace of dictionaries have related (but not equal) actors which may _help_ other humans using different strategies. The differentiation between then is **very** relevant as this affects perception of neutrality when _help_ is done.\n\n\n**1603:63:1** //Dicti≈çnƒÅria basibus dƒì auxiliƒ´s h≈´mƒÅnitƒÅtibus strictƒ´s//\n\nThis is stricter and more well know type of humanitarian aid. It MUST focus on immediate needs, which differentiate them from development aid.\n\n\n**[1603:26:21]** //Dicti≈çnƒÅria dƒì Iurum humanorum defensor//\n\nThis is the most generic type of human rights defender. In addition to defend some type of human rights, MUST not cause intentional harm to other human beings unless in self defense and not disproportional immediate to the danger.\n\n\n**[1603:26:36]** //Dicti≈çnƒÅria dƒì intraimperiƒ´s lƒìgisperƒ´tƒ´s per lƒìgƒìs certi≈çrƒÅt≈´//\n\nThis is a very strict type of **1603:26:21**. The main difference are the modi operandi : uses own country laws or it's signed international treaties to defend specific cases or reforms on country judicial system.\n\n**[1603:45:997]** //(needs be boostrapped)//\n\nDevelopment aid, while may be practiced as part of humanitarian operations to reduce likelihood of future need from foreigner help to do humanitarian aid, is not the same as humanitarian aid. \n\n\n**[1603:14:997]** //Dicti≈çnƒÅria dƒì relevƒÅminibus per bellƒ´s//\n\nMilitary relief is a type of intervention on a foreign country justified on reduce individual human suffering which already is not considered a formal peacekeeping operation.",,
50,,Quotes and other messages,,
50_1,,/**Public domain means that each major common issue only needs to be resolved once**/@eng-Latn,,
100,,NotƒÅte bene,,
100_1,,[HELP WANTED] Generated PDF don't have right fonts for all languages,,
100_1_1,,"First, sorry if this affects your loved language. We're working on this, but we are still not perfected.\n\nIf you have fonts installed on your computer, you very likely can still copy and paste from the eBook version.\n\nPlease note that all formats intended for machine processing will work fine.",,
100_2,,[Book with Wikidata Q] I want to help! Some translation is missing or is wrong! How to change it?,,
100_2_1,,"Most (but not all) concepts are using Wikidata Q. In fact, most of the time we improve Wikidata while preparing the dictionaries. Please check if the exact concept you want have a Q ID then click. There you can add translations.\n\nThe next release (likely weekly) will have your submissions without need to contact us directly.",,
100_3,,"[Book with Wikidata Q] I can find the Wikidata concept, but I'm unable to edit!",,
100_3_1,,"While Wikidata is more flexible than Wikipedia's (for example, it allows concepts without need to create Wikipedia pages) even Wikidata can have concepts which require creating an account and don't allow anonymous editing. Creating such an account and confirming email is faster than asking someone else's do it for you.\n\nHowever, while vandalism on Wikidata is rare, very few concepts will require an account with more contributions and not created very recently. If this is your case, help with the ones you can do alone and the rest ask someone else to add to you.",,
100_4,,I heard there is an interest in having C≈çdex beyond Latin language! How to do it?!,,
100_4_1,,"Please contact us. This book uses Latin (sometimes _dog Latin_) to document all other languages, but we obviously can automated generation of books for others using other writing systems and some reference language.",,
999,,@TODOs,,
999_1,,Add links to codex to search by last edits on Q itens on the current book. See https://wikidata-todo.toolforge.org/sparql_rc.php?,,
